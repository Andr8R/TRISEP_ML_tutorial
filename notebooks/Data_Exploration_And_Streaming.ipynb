{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRISEP ML Tutorial Part 1: Project overview and data visualization and streaming tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "I will assume everybody here is roughly familiar with physics of neutrinos and Water Cherenkov detectors.\n",
    "In this project we will tackle the task of classification of neutrino type ($\\nu_e$ or $\\nu_\\mu$) or rather the charged leptons resulting from the nuclear scatter ($e$ and  $\\mu$) as well as an irreducible background from neutral current $\\gamma$ production. The dataset comes from simulated Water Cherenkov detector called NuPRISM. NuPRISM is a proposed 'intermediate' detector for the Hyper-Kamiokande project. The detector has a cylindrical geometry and can be lowered and raised in a shaft to sample different energy distribution of incoming neutrinos! ![NUPRISM](../img/NUPRISM_diag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cylinder wall or 'barrel' and end-caps are lined with 'multi-PMT' or 'mPMT' modules arranged in a rectangular grid. Each mPMT is a dome with 19 PMTs arranged in two rings and one at the center:![mPMT](../img/mPMT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an event display where the barrel was 'unrolled':\n",
    "![eventdisp](../img/ev_disp.png) - you can clearly see a Cherenkov ring appearing\n",
    "The 'brightness' corresponds to charge collected by each PMT. Each PMT also tells us the arrival time of the signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the we will take a look at the data and how to organize streaming it in batches so that we can feed it to our neural model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! now that you are back lets see if we can see the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 wfedorko wfedorko 82G Jul 23 17:30 /data/TRISEP_data/NUPRISM.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls /data/TRISEP_data/NUPRISM.h5 -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly look what's inside... - import h5py, numpy etc and open for reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, time\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=h5py.File(\"/data/TRISEP_data/NUPRISM.h5\",\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keys()` will give us all the hdf5 datasets stored in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['energies', 'event_data', 'labels']>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the shapes of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900000, 16, 40, 38)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['event_data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 900k simulated scattering events here! labels are 0, 1, 2 for $\\gamma$,$e$ and $\\mu$ respectively. The 'event_data' contains only the barrel portion of the tank which has been 'unrolled'. The first dimension (900k) enumerates over the events, the second two dimensions (16,40) enumerate over the row and column in the module 'grid'. Finally last two dimensions enumerate over the PMT within the module (again there are 19 in each mPMT module) first 19 entries correspond to charge collected on a given PMT and last 19 correspond to the time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the object returned by the subscript looks like an array - we can subscript it and even do fancy indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [1.0128782e+00, 0.0000000e+00, 7.9039353e-01, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         ...,\n",
       "         [8.0274928e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          9.8659998e+02, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 9.8229999e+02, 0.0000000e+00]],\n",
       "\n",
       "        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 1.0651000e+03, 0.0000000e+00],\n",
       "         [4.4163281e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         ...,\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [3.7118652e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          9.8529999e+02, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 9.6490002e+02]],\n",
       "\n",
       "        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          9.6340002e+02, 0.0000000e+00, 9.6709998e+02],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 9.9220001e+02],\n",
       "         [0.0000000e+00, 0.0000000e+00, 1.5310415e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         ...,\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [1.0919875e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         ...,\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 1.3688321e+00, 1.3129321e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "        [[6.6636193e-01, 0.0000000e+00, 2.3644729e+00, ...,\n",
       "          0.0000000e+00, 9.9150000e+02, 9.6659998e+02],\n",
       "         [1.2039759e+00, 1.0671629e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         ...,\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "        [[1.1869018e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [1.4877930e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         ...,\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 1.1192518e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [4.1829556e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         ...,\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         ...,\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 9.5970001e+02],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 9.5959998e+02],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         ...,\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         ...,\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         ...,\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         ...,\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['event_data'][[42,1984],:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In fact the object is not a numpy array -it is a hdf5 `Dataset` object - the data itself lives on disk until we request it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h5py._hl.dataset.Dataset"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(f['event_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the dataset will make it difficult to load all at once into memory on many systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the bulk of the data is 81.5 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the bulk of the data is {:.1f} GB\".format( (f['event_data'].size * 4 / (1024**3)) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important feature of the dataset it is uncompressed and contiguous or 'unchunked':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset chunks: None compression: None\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset chunks: {} compression: {}\".format(f['event_data'].chunks,f['event_data'].compression))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has been prepared as contiguous and uncompressed so that we are not obliged to load it all in memory but we can access it very fast. BUT it will take more spave on disk. In the next section we will see an example of how to deal with datasets with these sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import and create a Dataset object - you are welcome to look at the [source](/edit/utils/data_handling.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to include the sources in the python search path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "currentdir = os.getcwd()\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_handling import WCH5Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class derives from the torch Dataset object. The two heavy lifters are the __init__ function and __getitem__ function.\n",
    "Let's look at what init does:  \n",
    "       \n",
    "```python\n",
    "        self.f=h5py.File(path,'r')\n",
    "        hdf5_event_data = self.f[\"event_data\"]\n",
    "        hdf5_labels=self.f[\"labels\"]\n",
    "        hdf5_energies=self.f[\"energies\"]\n",
    "\n",
    "        event_data_shape = hdf5_event_data.shape\n",
    "        event_data_offset = hdf5_event_data.id.get_offset()\n",
    "        event_data_dtype = hdf5_event_data.dtype         \n",
    "```\n",
    "      \n",
    "-here we opened the file and got the offsets, shapes, and data types of the datasets. Why are we doing this? This is because the hdf5 file is uncompressed and the datasets within are contiguous - this allows us to do memory mapping of the file. This is important with large datasets like this - where we are most like not going to be able to load everything into memory. Withh memory map we can only load what we need, when we need it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory map itself happens here:\n",
    "\n",
    "```python\n",
    "        self.event_data = np.memmap(path, mode='r', \n",
    "                                    shape=event_data_shape, \n",
    "                                    offset=event_data_offset, \n",
    "                                    dtype=event_data_dtype) \n",
    "```\n",
    "We will just load the labels and energies into memory - this is only several MB\n",
    "```python\n",
    "        self.labels = np.array(hdf5_labels)\n",
    "        self.energies = np.array(hdf5_energies)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of __init__ function computes indices for training, validation and testing sets, based on a random (but consistent) shuffle of events - this will be useful later when trainnig our model. We also provide a facility to only use a subset of the dataset. Why may we want to access the records in the file in randomized order. This really depends on how the dataset was created - for instance here we just concatenated a bunch of simulation files in order - so the examples are in blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['labels'][0::1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will definitelly want to avoid showing the model only photons then only electrons and then only muons - hence the index \n",
    "shuffling:\n",
    "```python\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    self.train_indices = indices[:-n_val-n_test]\n",
    "    self.val_indices = indices[-n_test-n_val:-n_test]\n",
    "    self.test_indices = indices[-n_test:]\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have the __getitem__ method - this provides functionality for the subscript [] operator. Only here we actually load the event_data that was requested:  \n",
    "```python\n",
    "        return np.array(self.event_data[index,:]),  self.labels[index], self.energies[index][0]       \n",
    "```\n",
    "-we return a tuple with three elements - first is the event 'image', second is the label, and third is the 'true' energy of the generated particle. If you look at the code you will notice that there is also a provision for providing a transform. This is very useful if you want to do data augmentation on-the-fly. E.g. we could flip the images to 'populate' the dataset to reflect the variability we expect in the dataset we will want to apply the model. We could also use it to pre-process the data on-the fly as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally we need the len method - this just needs to return how many exmples we have in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok let's instantiate the dataset and ask it for a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset=WCH5Dataset(\"/data/TRISEP_data/NUPRISM.h5\",val_split=0.1,test_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import matplotlib and tell it to plot inline in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some random event and label from the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "event, label, energy=dset[dset.train_indices[1984]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 and energy: 483.4703063964844 (MeV) \n"
     ]
    }
   ],
   "source": [
    "print(\"Label {} and energy: {} (MeV) \".format(label,energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/TRISEP_data/NUPRISM.h5'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to plot only the PMT charge for the 'center' PMT in mPMT modules - i believe this is at channel 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class is 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8),facecolor='w')\n",
    "plt.imshow(event[:,:,18],cmap='jet',origin='lower')\n",
    "ax.set_title('Event Data, center PMT',fontsize=20,fontweight='bold')\n",
    "print('class is {}'.format(label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also display the sum charge in the PMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class is 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8),facecolor='w')\n",
    "plt.imshow(np.sum(event[:,:,0:18],axis=-1),cmap='jet',origin='lower')\n",
    "ax.set_title('Event Data, charge sum in mPMT',fontsize=20,fontweight='bold')\n",
    "print('class is {}'.format(label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader objects and streaming the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets actually create DataLoader objects - one for each training, validation and testing set - but each DataLoader uses the same dataset -that way we keep only one open file (this is the 'standard' pytorch way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "train_iter=DataLoader(dset,batch_size=64,shuffle=False,sampler=SubsetRandomSampler(dset.train_indices),num_workers=4)\n",
    "val_iter=DataLoader(dset,batch_size=64,shuffle=False,sampler=SubsetRandomSampler(dset.val_indices),num_workers=4)\n",
    "test_iter=DataLoader(dset,batch_size=64,shuffle=False,sampler=SubsetRandomSampler(dset.test_indices),num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see the parameters - like batch_size and sampler - the sampler uses the indices we computed for the training, validation and testing set - if you use a sampler shuffle has to be False. On each iteration the DataLoader object will ask the dataset for a bunch of indices (calling the __getitem__ function we coded earlier) and then collate the data into a batch tensor. The collating can also be customized by providing collate_fn - but for now we will leave it with a default behavior. Did you notice the `num_workers` argument? if >0 this will enable multiprocessing - several processes will be reading examples (if supplied applying the augmentation transformation) and putting the data on queue that would be than 'consumed' by your training/evaluation process. We requested 4 CPUs for the job so we will use that. We are beating on the same storage with all threads - so if we aren't doing much preprocessing it doesn't make sense to make this too high..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how you would iterate over several batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_over_set(loader,loop_limit=3):\n",
    "\n",
    "    # Let's measure time that takes in each loop\n",
    "    trecord = np.zeros([loop_limit],dtype=np.float32)\n",
    "    t = time.time()\n",
    "    for iteration, batch in enumerate(loader):\n",
    "\n",
    "        data,label = batch\n",
    "\n",
    "        # Print out some content info\n",
    "        print('Iteration',iteration,'... time:',time.time()-t,'[s]')\n",
    "        print('    Labels:',label)\n",
    "\n",
    "        trecord[iteration] = time.time() - t\n",
    "        t = time.time()\n",
    "\n",
    "        # break when reaching the loop limit\n",
    "        if (iteration+1) == loop_limit:\n",
    "            break\n",
    "    return trecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convince yourself that the `data` and `label` are already tensors - which we could plug into our (future) model. Now let's iterate over first 40 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 ... time: 32.570629358291626 [s]\n",
      "    Labels: tensor([0., 2., 0., 2., 1., 2., 0., 0., 2., 0., 2., 1., 1., 0., 2., 2., 1., 0.,\n",
      "        1., 0., 1., 2., 1., 0., 1., 0., 2., 1., 1., 0., 0., 2., 0., 1., 1., 2.,\n",
      "        2., 0., 0., 0., 2., 2., 2., 2., 0., 2., 0., 0., 2., 2., 2., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 2., 1., 0.])\n",
      "Iteration 1 ... time: 2.3585901260375977 [s]\n",
      "    Labels: tensor([0., 2., 2., 1., 2., 2., 2., 0., 2., 2., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        2., 2., 1., 0., 2., 1., 1., 2., 2., 1., 0., 0., 0., 1., 0., 0., 0., 2.,\n",
      "        0., 0., 1., 1., 1., 2., 1., 1., 1., 0., 1., 2., 1., 0., 2., 2., 0., 0.,\n",
      "        2., 0., 2., 0., 1., 0., 1., 2., 0., 1.])\n",
      "Iteration 2 ... time: 0.002050638198852539 [s]\n",
      "    Labels: tensor([0., 1., 2., 2., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 2., 1., 2., 2., 2., 1., 1., 0., 1., 2., 0., 1., 1., 0., 1., 2.,\n",
      "        0., 2., 0., 0., 2., 0., 1., 0., 2., 2., 2., 1., 0., 0., 0., 2., 1., 0.,\n",
      "        1., 0., 0., 2., 0., 0., 0., 0., 0., 0.])\n",
      "Iteration 3 ... time: 0.0019123554229736328 [s]\n",
      "    Labels: tensor([1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 2., 2., 1., 2., 2., 1., 2., 2.,\n",
      "        1., 0., 0., 2., 2., 0., 1., 0., 0., 2., 0., 2., 1., 1., 0., 0., 1., 0.,\n",
      "        2., 0., 1., 1., 1., 0., 2., 0., 1., 0., 0., 1., 0., 1., 0., 2., 0., 1.,\n",
      "        1., 0., 0., 1., 2., 1., 0., 1., 2., 2.])\n",
      "Iteration 4 ... time: 20.503448963165283 [s]\n",
      "    Labels: tensor([2., 0., 0., 2., 0., 1., 1., 2., 2., 2., 2., 1., 2., 1., 1., 2., 0., 2.,\n",
      "        0., 1., 1., 0., 2., 0., 1., 0., 1., 1., 0., 0., 2., 0., 0., 2., 2., 0.,\n",
      "        1., 2., 2., 1., 0., 2., 2., 1., 2., 0., 1., 1., 2., 1., 0., 0., 0., 0.,\n",
      "        1., 2., 1., 0., 2., 1., 2., 2., 1., 1.])\n",
      "Iteration 5 ... time: 0.7916288375854492 [s]\n",
      "    Labels: tensor([2., 0., 2., 1., 0., 1., 1., 0., 1., 1., 2., 2., 0., 1., 1., 2., 2., 2.,\n",
      "        2., 1., 0., 2., 2., 1., 2., 1., 2., 0., 0., 1., 1., 1., 0., 2., 1., 2.,\n",
      "        0., 0., 0., 2., 2., 2., 1., 2., 0., 0., 1., 0., 1., 0., 2., 2., 0., 2.,\n",
      "        1., 2., 0., 1., 2., 2., 0., 2., 0., 0.])\n",
      "Iteration 6 ... time: 0.0018990039825439453 [s]\n",
      "    Labels: tensor([1., 1., 0., 0., 2., 2., 2., 1., 2., 2., 2., 0., 1., 2., 2., 0., 1., 0.,\n",
      "        2., 0., 1., 0., 2., 2., 0., 2., 0., 0., 2., 1., 1., 1., 2., 0., 0., 1.,\n",
      "        0., 0., 0., 2., 2., 0., 1., 1., 2., 2., 2., 0., 0., 0., 2., 0., 2., 1.,\n",
      "        0., 0., 0., 2., 1., 0., 0., 0., 0., 0.])\n",
      "Iteration 7 ... time: 0.0018854141235351562 [s]\n",
      "    Labels: tensor([1., 0., 2., 1., 0., 1., 2., 0., 1., 1., 2., 2., 2., 2., 2., 0., 1., 0.,\n",
      "        1., 1., 2., 0., 2., 1., 2., 1., 0., 1., 1., 2., 0., 1., 2., 2., 0., 2.,\n",
      "        1., 1., 0., 2., 1., 2., 1., 1., 1., 2., 2., 0., 1., 0., 1., 0., 2., 0.,\n",
      "        0., 1., 1., 1., 2., 1., 0., 0., 0., 0.])\n",
      "Iteration 8 ... time: 25.043397665023804 [s]\n",
      "    Labels: tensor([2., 1., 2., 0., 1., 1., 1., 2., 0., 1., 0., 1., 1., 2., 2., 0., 2., 0.,\n",
      "        0., 0., 2., 0., 1., 0., 0., 2., 1., 0., 2., 2., 1., 2., 1., 2., 1., 2.,\n",
      "        0., 0., 0., 2., 2., 2., 2., 0., 2., 0., 2., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 1., 1., 2., 1., 0., 0., 2.])\n",
      "Iteration 9 ... time: 0.0020456314086914062 [s]\n",
      "    Labels: tensor([2., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 2., 2., 1., 1., 0., 2., 1., 2., 2., 2., 0., 0., 0., 0., 1., 2.,\n",
      "        1., 2., 2., 1., 1., 2., 1., 1., 0., 1., 2., 2., 0., 1., 0., 2., 1., 0.,\n",
      "        0., 0., 1., 0., 2., 2., 1., 1., 2., 2.])\n",
      "Iteration 10 ... time: 0.0019102096557617188 [s]\n",
      "    Labels: tensor([2., 2., 1., 2., 2., 2., 0., 2., 2., 2., 0., 2., 2., 2., 1., 2., 2., 1.,\n",
      "        2., 1., 1., 1., 2., 1., 2., 2., 2., 2., 2., 0., 2., 1., 0., 0., 1., 0.,\n",
      "        2., 0., 0., 2., 1., 2., 0., 1., 0., 2., 2., 0., 0., 0., 1., 2., 2., 1.,\n",
      "        2., 2., 0., 2., 0., 1., 0., 0., 0., 2.])\n",
      "Iteration 11 ... time: 0.0018177032470703125 [s]\n",
      "    Labels: tensor([0., 1., 0., 2., 0., 0., 2., 1., 0., 2., 2., 0., 0., 1., 2., 0., 1., 2.,\n",
      "        1., 2., 1., 2., 2., 0., 1., 1., 2., 0., 2., 2., 2., 2., 2., 1., 1., 1.,\n",
      "        0., 1., 1., 2., 1., 1., 0., 0., 0., 1., 0., 0., 2., 0., 1., 0., 0., 2.,\n",
      "        1., 0., 2., 2., 0., 0., 1., 1., 0., 1.])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ecc93cf70987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloop_over_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-ac91a9992a3f>\u001b[0m in \u001b[0;36mloop_over_set\u001b[0;34m(loader, loop_limit)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloop_limit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loop_over_set(train_iter, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OMG that was slow... and we aren't even oing anything with the data- do you notice that roughly every 4th iteration the time it takes to give a batch is huge? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch manager (`SLURM` on Compute Canada) gives us a location of fast storage we are supposed to use for accessing repeatedly a dataset with low latency. Any system ought to have a local fast scratch for purposes like this. Different batch managers may or may not give you a specific location for your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/localscratch/wfedorko.22473141.0\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['SLURM_TMPDIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's copy the dataset there and repeat the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "!cp /scratch/wfedorko/TRIUMF_DS_NUPRISM/merged_IWCDmPMT_varyE.h5 ${SLURM_TMPDIR}/ -v\n",
    "tdiff=time.time()-t\n",
    "print(\"that took {} seconds\".format(tdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset=WCH5Dataset(os.environ['SLURM_TMPDIR']+\"/merged_IWCDmPMT_varyE.h5\",val_split=0.1,test_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter=DataLoader(dset,batch_size=64,shuffle=False,sampler=SubsetRandomSampler(dset.train_indices),num_workers=4)\n",
    "val_iter=DataLoader(dset,batch_size=64,shuffle=False,sampler=SubsetRandomSampler(dset.val_indices),num_workers=4)\n",
    "test_iter=DataLoader(dset,batch_size=64,shuffle=False,sampler=SubsetRandomSampler(dset.test_indices),num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 ... time: 0.39338254928588867 [s]\n",
      "    Labels: tensor([1., 1., 1., 2., 2., 1., 0., 1., 1., 0., 2., 0., 0., 1., 0., 0., 2., 1.,\n",
      "        0., 2., 1., 2., 0., 2., 0., 1., 0., 0., 1., 0., 0., 2., 0., 1., 2., 0.,\n",
      "        2., 1., 2., 0., 2., 2., 1., 0., 1., 0., 0., 0., 2., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 2., 2., 0., 2., 2., 0., 1.])\n",
      "Iteration 1 ... time: 0.006192922592163086 [s]\n",
      "    Labels: tensor([0., 2., 2., 2., 2., 1., 1., 1., 1., 1., 0., 2., 0., 0., 2., 1., 2., 2.,\n",
      "        1., 1., 2., 2., 0., 1., 1., 0., 2., 2., 0., 1., 0., 1., 1., 2., 1., 0.,\n",
      "        2., 0., 0., 1., 2., 2., 0., 0., 0., 0., 2., 1., 2., 2., 2., 0., 1., 1.,\n",
      "        1., 0., 0., 2., 2., 1., 2., 2., 2., 1.])\n",
      "Iteration 2 ... time: 0.0015833377838134766 [s]\n",
      "    Labels: tensor([2., 1., 0., 2., 1., 2., 1., 1., 2., 0., 2., 1., 2., 0., 1., 2., 0., 2.,\n",
      "        1., 1., 2., 1., 2., 2., 1., 1., 2., 1., 0., 2., 1., 0., 0., 2., 0., 2.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 2., 2., 1., 0., 2., 2., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 2., 1., 2., 1., 2., 2.])\n",
      "Iteration 3 ... time: 0.0015835762023925781 [s]\n",
      "    Labels: tensor([1., 2., 1., 0., 2., 1., 2., 1., 2., 2., 1., 0., 1., 2., 1., 2., 0., 1.,\n",
      "        1., 0., 2., 1., 0., 2., 2., 2., 0., 2., 2., 1., 1., 2., 0., 1., 1., 2.,\n",
      "        2., 1., 2., 1., 0., 1., 2., 0., 2., 1., 2., 1., 1., 2., 2., 1., 0., 2.,\n",
      "        2., 2., 1., 2., 1., 2., 2., 0., 0., 2.])\n",
      "Iteration 4 ... time: 0.12232828140258789 [s]\n",
      "    Labels: tensor([0., 2., 0., 1., 1., 0., 0., 0., 0., 1., 2., 1., 1., 0., 1., 2., 1., 1.,\n",
      "        2., 1., 2., 2., 0., 0., 1., 2., 2., 0., 1., 1., 2., 2., 2., 0., 1., 1.,\n",
      "        1., 0., 2., 1., 2., 1., 0., 0., 1., 0., 2., 1., 0., 1., 1., 1., 0., 0.,\n",
      "        2., 0., 1., 2., 0., 0., 0., 1., 2., 2.])\n",
      "Iteration 5 ... time: 0.0015425682067871094 [s]\n",
      "    Labels: tensor([2., 2., 2., 2., 0., 0., 1., 0., 1., 1., 2., 2., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 2., 2., 2., 1., 2., 0., 1., 2., 2., 2., 2., 2., 0.,\n",
      "        1., 0., 2., 1., 1., 2., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 2.,\n",
      "        0., 2., 1., 2., 0., 0., 0., 2., 0., 1.])\n",
      "Iteration 6 ... time: 0.003675699234008789 [s]\n",
      "    Labels: tensor([1., 0., 2., 0., 1., 0., 1., 2., 1., 2., 1., 2., 0., 2., 0., 0., 1., 1.,\n",
      "        1., 2., 2., 2., 2., 0., 2., 0., 0., 2., 0., 2., 2., 0., 1., 2., 1., 1.,\n",
      "        1., 2., 1., 0., 0., 0., 1., 1., 2., 2., 0., 0., 2., 0., 0., 2., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 1., 1.])\n",
      "Iteration 7 ... time: 0.0015604496002197266 [s]\n",
      "    Labels: tensor([2., 2., 0., 0., 2., 1., 0., 1., 0., 2., 0., 1., 0., 2., 1., 1., 0., 2.,\n",
      "        1., 2., 0., 2., 2., 0., 0., 1., 0., 0., 1., 1., 0., 2., 2., 2., 1., 2.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 2., 2., 1., 0., 1., 2., 2., 1., 2., 2., 1.,\n",
      "        1., 1., 2., 2., 1., 0., 2., 2., 0., 2.])\n",
      "Iteration 8 ... time: 0.11562776565551758 [s]\n",
      "    Labels: tensor([1., 0., 1., 0., 1., 2., 1., 0., 1., 2., 2., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 2., 2., 1., 2., 1., 0., 1., 1., 2., 0.,\n",
      "        2., 1., 2., 1., 0., 1., 2., 2., 1., 2., 1., 1., 2., 2., 2., 2., 1., 0.,\n",
      "        2., 2., 1., 1., 1., 2., 0., 2., 1., 1.])\n",
      "Iteration 9 ... time: 0.007471799850463867 [s]\n",
      "    Labels: tensor([2., 0., 2., 2., 2., 1., 2., 0., 1., 2., 0., 1., 2., 0., 0., 2., 0., 2.,\n",
      "        0., 1., 0., 0., 1., 2., 1., 0., 2., 0., 2., 1., 2., 1., 2., 1., 1., 1.,\n",
      "        2., 0., 2., 0., 1., 1., 2., 1., 0., 1., 0., 1., 1., 1., 0., 0., 2., 0.,\n",
      "        1., 2., 2., 2., 1., 1., 2., 2., 2., 1.])\n",
      "Iteration 10 ... time: 0.004614114761352539 [s]\n",
      "    Labels: tensor([2., 2., 0., 2., 0., 2., 2., 2., 0., 2., 2., 0., 2., 1., 0., 0., 2., 0.,\n",
      "        0., 1., 2., 2., 0., 2., 2., 1., 0., 1., 2., 1., 1., 0., 0., 0., 2., 0.,\n",
      "        1., 0., 2., 2., 2., 0., 2., 1., 1., 1., 1., 2., 0., 1., 2., 0., 1., 2.,\n",
      "        1., 0., 2., 0., 2., 0., 2., 0., 1., 1.])\n",
      "Iteration 11 ... time: 0.0015728473663330078 [s]\n",
      "    Labels: tensor([0., 1., 1., 2., 1., 1., 1., 1., 1., 2., 2., 1., 2., 2., 2., 1., 1., 1.,\n",
      "        1., 0., 2., 2., 2., 0., 1., 0., 1., 2., 0., 1., 2., 0., 0., 0., 1., 0.,\n",
      "        1., 2., 0., 1., 2., 0., 1., 2., 2., 2., 0., 0., 2., 0., 2., 2., 2., 0.,\n",
      "        0., 0., 2., 0., 2., 1., 1., 1., 2., 1.])\n",
      "Iteration 12 ... time: 0.12614107131958008 [s]\n",
      "    Labels: tensor([1., 0., 1., 0., 0., 2., 0., 2., 0., 0., 2., 0., 1., 0., 0., 1., 0., 2.,\n",
      "        2., 1., 1., 0., 2., 0., 1., 1., 0., 2., 1., 1., 0., 0., 0., 2., 2., 1.,\n",
      "        0., 1., 2., 1., 1., 0., 0., 1., 0., 0., 1., 1., 2., 2., 1., 2., 2., 2.,\n",
      "        1., 2., 1., 1., 1., 2., 0., 0., 2., 1.])\n",
      "Iteration 13 ... time: 0.02040410041809082 [s]\n",
      "    Labels: tensor([2., 1., 0., 2., 1., 2., 1., 1., 1., 2., 0., 2., 1., 0., 2., 2., 1., 0.,\n",
      "        1., 1., 1., 2., 2., 2., 0., 1., 1., 2., 0., 1., 0., 2., 1., 0., 0., 1.,\n",
      "        2., 1., 0., 2., 0., 2., 2., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 2., 1., 0., 0., 0., 0., 0.])\n",
      "Iteration 14 ... time: 0.004637241363525391 [s]\n",
      "    Labels: tensor([0., 2., 1., 1., 0., 1., 0., 0., 0., 2., 0., 2., 1., 2., 0., 2., 1., 0.,\n",
      "        1., 1., 2., 1., 2., 0., 2., 1., 2., 0., 1., 2., 1., 0., 2., 1., 2., 2.,\n",
      "        1., 1., 2., 2., 0., 1., 1., 0., 2., 1., 2., 1., 0., 0., 2., 2., 2., 2.,\n",
      "        0., 1., 1., 2., 0., 2., 2., 0., 0., 2.])\n",
      "Iteration 15 ... time: 0.0015654563903808594 [s]\n",
      "    Labels: tensor([2., 0., 0., 1., 0., 1., 1., 2., 2., 1., 0., 0., 1., 2., 0., 1., 2., 2.,\n",
      "        2., 2., 2., 1., 1., 1., 1., 0., 2., 2., 1., 0., 1., 1., 1., 0., 2., 1.,\n",
      "        1., 1., 2., 0., 1., 1., 2., 2., 2., 2., 0., 1., 2., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 2., 0., 2., 1.])\n",
      "Iteration 16 ... time: 0.10747361183166504 [s]\n",
      "    Labels: tensor([0., 0., 0., 0., 0., 2., 0., 1., 0., 2., 1., 0., 1., 1., 1., 0., 0., 2.,\n",
      "        1., 0., 1., 1., 0., 0., 2., 1., 1., 1., 0., 2., 1., 0., 2., 0., 1., 2.,\n",
      "        2., 2., 2., 0., 0., 0., 0., 2., 1., 1., 0., 0., 0., 0., 2., 1., 2., 1.,\n",
      "        0., 2., 2., 1., 2., 1., 2., 0., 2., 2.])\n",
      "Iteration 17 ... time: 0.026961326599121094 [s]\n",
      "    Labels: tensor([0., 2., 1., 0., 2., 2., 2., 2., 0., 0., 2., 0., 0., 1., 2., 2., 0., 2.,\n",
      "        0., 1., 1., 0., 0., 1., 2., 1., 1., 0., 0., 1., 1., 0., 2., 1., 2., 1.,\n",
      "        2., 2., 0., 2., 1., 1., 2., 1., 1., 2., 1., 1., 0., 0., 1., 2., 2., 2.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 1., 1.])\n",
      "Iteration 18 ... time: 0.002665281295776367 [s]\n",
      "    Labels: tensor([1., 0., 1., 0., 2., 0., 0., 2., 1., 1., 2., 2., 1., 0., 2., 2., 0., 1.,\n",
      "        2., 0., 2., 0., 1., 1., 2., 2., 0., 2., 0., 2., 0., 1., 1., 1., 0., 2.,\n",
      "        2., 0., 0., 0., 1., 0., 1., 1., 2., 2., 2., 2., 0., 2., 2., 0., 0., 1.,\n",
      "        1., 2., 2., 0., 0., 2., 0., 0., 0., 2.])\n",
      "Iteration 19 ... time: 0.0013341903686523438 [s]\n",
      "    Labels: tensor([1., 0., 0., 2., 0., 0., 2., 0., 0., 1., 1., 0., 2., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 2., 2., 0., 2., 2., 2., 1., 1., 2., 2., 2., 1., 0., 1., 2.,\n",
      "        1., 2., 1., 2., 0., 1., 1., 1., 2., 2., 1., 2., 2., 1., 1., 1., 1., 1.,\n",
      "        0., 2., 2., 0., 2., 0., 1., 2., 2., 2.])\n",
      "Iteration 20 ... time: 0.10456180572509766 [s]\n",
      "    Labels: tensor([2., 1., 2., 0., 1., 1., 2., 2., 0., 2., 2., 2., 1., 0., 2., 1., 0., 2.,\n",
      "        1., 1., 1., 2., 2., 0., 2., 2., 2., 1., 2., 1., 0., 0., 2., 1., 0., 1.,\n",
      "        2., 1., 0., 0., 1., 2., 1., 1., 0., 0., 2., 0., 2., 0., 2., 2., 0., 2.,\n",
      "        2., 1., 2., 2., 2., 0., 1., 2., 2., 1.])\n",
      "Iteration 21 ... time: 0.029560565948486328 [s]\n",
      "    Labels: tensor([0., 0., 1., 1., 2., 2., 0., 2., 0., 1., 1., 2., 2., 2., 2., 2., 2., 1.,\n",
      "        1., 0., 2., 1., 1., 1., 1., 2., 1., 2., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 2., 2., 1., 2., 0., 2., 1., 0., 1., 1., 0., 0.,\n",
      "        2., 0., 0., 0., 1., 2., 2., 2., 2., 0.])\n",
      "Iteration 22 ... time: 0.00418543815612793 [s]\n",
      "    Labels: tensor([1., 1., 0., 0., 1., 0., 0., 1., 1., 2., 2., 1., 1., 2., 1., 1., 2., 1.,\n",
      "        1., 2., 2., 0., 2., 0., 1., 1., 1., 1., 0., 1., 1., 2., 1., 0., 2., 1.,\n",
      "        1., 2., 2., 0., 1., 0., 0., 2., 0., 1., 0., 1., 1., 1., 0., 2., 0., 2.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 0., 1., 2.])\n",
      "Iteration 23 ... time: 0.0015497207641601562 [s]\n",
      "    Labels: tensor([0., 0., 0., 0., 1., 2., 1., 1., 2., 0., 1., 2., 0., 2., 2., 2., 0., 0.,\n",
      "        1., 2., 1., 1., 0., 1., 1., 2., 2., 0., 0., 1., 1., 0., 0., 2., 1., 0.,\n",
      "        0., 0., 2., 1., 0., 0., 1., 0., 2., 1., 2., 0., 1., 0., 2., 0., 0., 0.,\n",
      "        1., 2., 1., 1., 1., 2., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24 ... time: 0.10514974594116211 [s]\n",
      "    Labels: tensor([2., 0., 0., 2., 0., 1., 2., 2., 1., 2., 0., 1., 1., 2., 0., 0., 2., 0.,\n",
      "        2., 0., 0., 0., 1., 2., 1., 2., 2., 1., 1., 1., 2., 0., 2., 1., 0., 2.,\n",
      "        1., 0., 2., 1., 1., 2., 0., 1., 2., 1., 1., 2., 0., 2., 2., 1., 2., 0.,\n",
      "        2., 1., 0., 2., 1., 1., 1., 1., 0., 0.])\n",
      "Iteration 25 ... time: 0.031655311584472656 [s]\n",
      "    Labels: tensor([2., 2., 1., 1., 2., 0., 0., 0., 0., 2., 2., 1., 2., 0., 1., 0., 2., 2.,\n",
      "        0., 0., 2., 2., 0., 2., 1., 1., 1., 2., 0., 0., 0., 2., 2., 2., 2., 2.,\n",
      "        2., 1., 0., 2., 1., 1., 0., 1., 2., 1., 0., 2., 0., 0., 2., 1., 0., 0.,\n",
      "        1., 0., 1., 2., 1., 2., 1., 2., 0., 0.])\n",
      "Iteration 26 ... time: 0.0014500617980957031 [s]\n",
      "    Labels: tensor([2., 2., 0., 2., 0., 0., 2., 2., 0., 2., 1., 2., 1., 1., 2., 2., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 2., 2., 2., 0., 1., 1., 0., 1., 1., 0., 1., 2.,\n",
      "        2., 2., 1., 1., 2., 1., 1., 2., 0., 0., 1., 2., 0., 0., 1., 0., 1., 2.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 2., 0., 2.])\n",
      "Iteration 27 ... time: 0.0015132427215576172 [s]\n",
      "    Labels: tensor([2., 1., 1., 2., 0., 1., 2., 0., 0., 0., 1., 0., 1., 2., 2., 0., 0., 2.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 2., 2., 0., 1.,\n",
      "        2., 0., 1., 1., 2., 2., 0., 2., 2., 0., 0., 0., 0., 0., 0., 2., 2., 2.,\n",
      "        1., 1., 2., 0., 1., 0., 1., 2., 1., 2.])\n",
      "Iteration 28 ... time: 0.10300135612487793 [s]\n",
      "    Labels: tensor([2., 2., 0., 1., 2., 2., 0., 0., 2., 1., 2., 2., 0., 0., 1., 0., 0., 1.,\n",
      "        2., 0., 1., 0., 1., 2., 1., 2., 2., 2., 0., 1., 2., 1., 2., 1., 0., 1.,\n",
      "        2., 2., 1., 1., 2., 1., 1., 1., 0., 2., 1., 2., 0., 1., 2., 1., 0., 0.,\n",
      "        1., 2., 2., 0., 1., 2., 2., 1., 0., 1.])\n",
      "Iteration 29 ... time: 0.03930544853210449 [s]\n",
      "    Labels: tensor([2., 2., 2., 2., 1., 1., 0., 1., 1., 0., 1., 0., 0., 2., 0., 1., 2., 2.,\n",
      "        2., 1., 0., 0., 2., 0., 2., 0., 1., 0., 0., 2., 1., 2., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 2., 0., 2., 1., 0., 1., 2., 2., 1., 2., 2., 2.,\n",
      "        0., 0., 1., 2., 0., 0., 1., 2., 1., 1.])\n",
      "Iteration 30 ... time: 0.0014123916625976562 [s]\n",
      "    Labels: tensor([0., 0., 2., 2., 2., 2., 2., 2., 2., 0., 2., 1., 0., 0., 0., 0., 2., 0.,\n",
      "        2., 2., 2., 1., 1., 2., 0., 2., 2., 0., 0., 0., 2., 0., 0., 1., 0., 2.,\n",
      "        1., 0., 2., 1., 1., 0., 1., 0., 2., 1., 2., 1., 0., 1., 1., 2., 0., 0.,\n",
      "        0., 0., 2., 0., 0., 2., 2., 1., 0., 0.])\n",
      "Iteration 31 ... time: 0.0015625953674316406 [s]\n",
      "    Labels: tensor([0., 2., 2., 2., 0., 0., 2., 0., 0., 0., 1., 0., 1., 1., 2., 1., 0., 1.,\n",
      "        2., 2., 1., 2., 1., 2., 2., 1., 1., 0., 1., 2., 2., 1., 2., 0., 1., 1.,\n",
      "        1., 0., 0., 2., 0., 1., 1., 2., 1., 2., 1., 1., 0., 0., 1., 0., 0., 2.,\n",
      "        1., 2., 1., 2., 1., 1., 1., 0., 0., 0.])\n",
      "Iteration 32 ... time: 0.10083794593811035 [s]\n",
      "    Labels: tensor([2., 1., 0., 2., 1., 2., 1., 1., 0., 2., 2., 1., 1., 1., 1., 2., 2., 2.,\n",
      "        2., 0., 0., 0., 2., 1., 0., 1., 0., 2., 2., 1., 1., 2., 0., 2., 2., 2.,\n",
      "        1., 2., 2., 1., 2., 1., 1., 1., 1., 2., 2., 1., 1., 1., 1., 2., 2., 0.,\n",
      "        0., 0., 2., 1., 1., 0., 1., 0., 0., 2.])\n",
      "Iteration 33 ... time: 0.027446269989013672 [s]\n",
      "    Labels: tensor([2., 2., 2., 0., 0., 2., 0., 2., 0., 2., 1., 2., 0., 0., 0., 1., 1., 2.,\n",
      "        0., 0., 1., 0., 2., 0., 1., 2., 0., 1., 0., 1., 0., 2., 0., 1., 2., 0.,\n",
      "        0., 0., 0., 2., 2., 0., 0., 2., 1., 0., 2., 1., 0., 2., 2., 1., 1., 2.,\n",
      "        2., 1., 0., 1., 1., 1., 1., 0., 2., 2.])\n",
      "Iteration 34 ... time: 0.0017421245574951172 [s]\n",
      "    Labels: tensor([2., 1., 2., 2., 1., 0., 0., 1., 1., 0., 0., 2., 0., 1., 2., 1., 1., 0.,\n",
      "        2., 0., 2., 1., 1., 1., 2., 2., 2., 2., 0., 1., 1., 1., 2., 0., 2., 1.,\n",
      "        0., 0., 1., 1., 0., 2., 0., 2., 2., 0., 0., 1., 2., 0., 1., 1., 2., 2.,\n",
      "        0., 2., 2., 0., 2., 2., 0., 0., 1., 0.])\n",
      "Iteration 35 ... time: 0.0014324188232421875 [s]\n",
      "    Labels: tensor([1., 0., 1., 0., 2., 0., 1., 1., 0., 1., 0., 2., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 2., 0., 0., 2., 2., 1., 0., 0., 2., 2., 2., 0., 0., 0., 1., 0., 2.,\n",
      "        0., 0., 0., 0., 2., 2., 0., 0., 1., 0., 0., 0., 0., 2., 2., 0., 0., 0.,\n",
      "        1., 1., 2., 1., 0., 0., 0., 0., 1., 2.])\n",
      "Iteration 36 ... time: 0.09908771514892578 [s]\n",
      "    Labels: tensor([1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 2., 1., 2., 2., 2., 1., 0.,\n",
      "        2., 2., 0., 2., 1., 1., 0., 0., 1., 0., 0., 2., 2., 2., 0., 2., 1., 0.,\n",
      "        0., 0., 0., 2., 1., 2., 1., 1., 1., 2., 0., 0., 0., 1., 2., 1., 1., 1.,\n",
      "        2., 2., 2., 2., 2., 1., 0., 2., 2., 0.])\n",
      "Iteration 37 ... time: 0.03413891792297363 [s]\n",
      "    Labels: tensor([2., 2., 2., 2., 1., 0., 1., 0., 1., 0., 0., 2., 2., 1., 0., 2., 1., 1.,\n",
      "        2., 2., 2., 0., 1., 0., 0., 2., 1., 1., 2., 0., 0., 2., 1., 1., 0., 1.,\n",
      "        2., 0., 0., 0., 1., 2., 0., 2., 0., 0., 0., 2., 2., 0., 1., 0., 2., 1.,\n",
      "        2., 0., 2., 0., 1., 0., 2., 2., 1., 1.])\n",
      "Iteration 38 ... time: 0.0014564990997314453 [s]\n",
      "    Labels: tensor([2., 2., 2., 2., 0., 0., 2., 2., 0., 0., 0., 1., 0., 1., 2., 0., 2., 0.,\n",
      "        2., 1., 2., 0., 0., 0., 2., 1., 2., 0., 1., 1., 0., 2., 2., 0., 0., 2.,\n",
      "        0., 2., 0., 1., 0., 2., 0., 2., 1., 2., 0., 1., 2., 0., 2., 0., 1., 0.,\n",
      "        1., 2., 2., 2., 0., 0., 1., 2., 1., 2.])\n",
      "Iteration 39 ... time: 0.0016117095947265625 [s]\n",
      "    Labels: tensor([1., 1., 0., 2., 1., 1., 0., 1., 2., 1., 2., 1., 1., 1., 1., 2., 1., 0.,\n",
      "        2., 0., 1., 2., 0., 1., 2., 1., 0., 1., 1., 1., 2., 2., 1., 2., 1., 1.,\n",
      "        2., 0., 2., 2., 0., 0., 1., 2., 0., 0., 2., 1., 2., 1., 0., 0., 0., 0.,\n",
      "        2., 2., 0., 0., 2., 1., 1., 1., 0., 1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.3971002 , 0.00924706, 0.00454521, 0.00485611, 0.1251483 ,\n",
       "       0.00410581, 0.00636053, 0.00424099, 0.11881042, 0.0102489 ,\n",
       "       0.00733089, 0.0042491 , 0.12887645, 0.02322483, 0.00766492,\n",
       "       0.00466919, 0.11041856, 0.03000998, 0.00548697, 0.00416946,\n",
       "       0.10714102, 0.03271365, 0.00690269, 0.00406194, 0.10816264,\n",
       "       0.03446817, 0.00417995, 0.0039587 , 0.10596228, 0.04212618,\n",
       "       0.00401545, 0.00505567, 0.10406089, 0.03024292, 0.00436854,\n",
       "       0.00369549, 0.10205698, 0.03704715, 0.00408864, 0.0042901 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop_over_set(train_iter, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok - way faster - even though it took a long time initially to copy the dataset - it's going to remove the bottleneck of data access during training - especially that we are going to be looping over the dataset many times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to get familiar with the data. Plot different event in different classes. Energy sums and histograms. Time histograms etc. Can you 'spot' the differences between classes 'by eye'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And remember to clean up!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed '/localscratch/wfedorko.22473141.0/merged_IWCDmPMT_varyE.h5'\r\n"
     ]
    }
   ],
   "source": [
    "!rm -v ${SLURM_TMPDIR}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
